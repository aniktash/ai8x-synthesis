# CHW (big data) configuration for Rock-Paper-Scissors 

arch: ai85net5
dataset: RPS

# Define layer parameters in order of the layer sequence
layers:
#- pad: 1
#  #activate: ReLU
#  out_offset: 0x2000
#  processors: 0x0000000000000007
#  data_format: HWC
#  op: conv2d
#- max_pool: 2
#  pool_stride: 2
#  pad: 1
#  activate: ReLU
#  out_offset: 0x0000
#  #processors: 0x00000003fffffff0
#  processors: 0x0000000000000007
#  data_format: HWC  #addition
#  op: conv2d
#- max_pool: 2
#  pool_stride: 2
#  pad: 1
#  activate: ReLU
#  out_offset: 0x2000
#  processors: 0x0003fffffff00000
#  op: conv2d
#- max_pool: 2
#  pool_stride: 2
#  pad: 1
#  activate: ReLU
#  #out_offset: 0x0000
#  out_offset: 0x2000
#  processors: 0x0003fffffff00000
#  #processors: 0xfffffffffffffff0
#  op: conv2d
#- max_pool: 2
#  pool_stride: 2
#  pad: 1
#  activate: ReLU
#  #out_offset: 0x0000
#  out_offset: 0x2000
#  processors: 0x000000003fffffff
#  op: conv2d
#ORIG:
#- pad: 1
#  activate: ReLU
#  #out_offset: 0x0000
#  out_offset: 0x2000
#  processors: 0x3fffffff00000000
#  op: conv2d
- max_pool: 16
  pool_stride: 8
  pad: 1
  activate: ReLU
  out_offset: 0x0000
  #processors: 0x3fffffff00000000
  #processors: 0x0000000700000000
  processors: 0x0000000000000007
  data_format: HWC  #addition
  op: conv2d
  #output_shift: 1
- op: mlp
  flatten: true
  out_offset: 0x1000
  output_width: 32
  #processors: 0x000000003fffffff
  #processors: 0x0000000000000001
  processors: 0x0000000000000010
#  output_shift: 0
